{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e13172e1",
   "metadata": {},
   "source": [
    "# We will import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1d8d897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cell runing witout error\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "print('the cell runing witout error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc4b55",
   "metadata": {},
   "source": [
    "# We will using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3577805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10500 images belonging to 7 classes.\n",
      "Found 2100 images belonging to 7 classes.\n",
      "the cell runing without error\n"
     ]
    }
   ],
   "source": [
    "#we will give the path of our Dataset which contains the learning and validation data\n",
    "train_data_dir =r'C:\\Users\\21260\\Projet\\Face_Recognition\\src\\resources\\Data\\Mydatabase\\Train'\n",
    "\n",
    "validation_dir =r'C:\\Users\\21260\\Projet\\Face_Recognition\\src\\resources\\Data\\Mydatabase\\Validation'\n",
    "\n",
    "#in this part of code we will increase the data\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,  horizontal_flip=True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory( train_data_dir, shuffle=False, target_size=(224, 224),batch_size = 32, class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( validation_dir, target_size=(224, 224),batch_size = 32,class_mode='categorical')\n",
    "print('the cell runing without error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45715b6f",
   "metadata": {},
   "source": [
    "# we will create the architecture of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d93176bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the cell was executed without error\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "print(' the cell was executed without error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c47f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop,SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "#//checking checkpoint for selecting the best model for the emotion detection and save the best model with minimum validation loss having the name written on it in the current working folder\n",
    "checkpoint = ModelCheckpoint('./P19.h5',\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "\n",
    "#//reduce_lr will also monitor the validation loss \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.1,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_lr=.000001)\n",
    "#callb = [earlystop, checkpoint, reduce_lr]\n",
    "\n",
    "call=[ checkpoint,reduce_lr]\n",
    "\n",
    "\n",
    "#loss  est La valeur ou bien fonction de perte qui sera minimis√©e\n",
    "from keras.optimizers import RMSprop,SGD,Adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])\n",
    "batch_size=128\n",
    "#//This last block of codes will train our codes with the given parameters where it will fit train generator for training epochs to 25, callbacks will call the earlystop, checkpoint and reduce_lr and validation data will be equal to validation generator which was created on the first execution \n",
    "history = model.fit_generator(generator=train_gen,steps_per_epoch=train_gen.n/batch_size, epochs=10,validation_data=validation_generator,callbacks=call,validation_steps=validation_generator.n/batch_size)\n",
    "# list all data in history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ae12f",
   "metadata": {},
   "source": [
    "# We will print the history of our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d091f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys()) \n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71845ec0",
   "metadata": {},
   "source": [
    "# we will save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:\\Users\\21260\\Projet\\Face_Recognition\\src\\CNN\\final_model_CNN.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
